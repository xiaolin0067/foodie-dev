https://www.elastic.co/cn/

Lucene：全文搜索的Java类库，就是一个jar包
Solr：基于Lucene进行封装，国外大厂在用
elasticsearch：基于Lucene进行封装，提供restful风格json接口，扩展性高

ES核心术语
索引index：相当于一张表
类型type：index的逻辑类型，7.*版本后弃用
文档document：相当于表记录，每一行记录
字段fields：列
映射mapping：结构定义
近实时NRT：near real time
节点node：每一个服务器
share：分片，存储数据
replica：分片的备份

倒排索引：根据属性来确定记录位置，称之为倒排索引。
索引表包含：属性值，属性值所在记录地址，属性词频与属性在记录中的位置

ES安装
tar -zxf elasticsearch-7.4.2-linux-x86_64.tar.gz
mv elasticsearch-7.4.2 /usr/local/
cd /usr/local/elasticsearch-7.4.2/
mkdir data
cd config
调整ES配置
vim elasticsearch.yml
  # 自定义集群名称
  cluster.name: my-es-cluster
  # 自定义节点名称
  node.name: es-node1
  # 修改数据存储目录
  path.data: /usr/local/elasticsearch-7.4.2/data
  # 修改日志存储目录
  path.logs: /usr/local/elasticsearch-7.4.2/logs
  # 关闭访问限制
  network.host: 0.0.0.0
  # 发现节点
  cluster.initial_master_nodes: ["es-node1"]
vim jvm.options
  # 虚拟机内存不足，调小为128MB
  -Xms128m
  -Xmx128m
注意：ES不可使用root用户启动，需要创建一个其他用户进行启动
useradd esuser
chown -R esuser:esuser elasticsearch-7.4.2/
切换为esuser启动发现报错：
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]
[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
需要进行如下配置
vim /etc/security/limits.conf
插入如下代码：
* soft nofile 65536
* hard nofile 131072
* soft nproc 2048
* soft nproc 4096
编辑系统文件
vim /etc/sysctl.conf
插入配置
vm.max_map_count=262145
刷新配置
sysctl -p
启动：
cd /usr/local/elasticsearch-7.4.2/bin/
su esuser
前台启动
./elasticsearch
后台启动
./elasticsearch -d

elasticsearch图形化管理工具：elasticsearch-header
安装方式：
1、科学上网，谷歌商店搜索elasticsearch安装
2、下载源码运行
https://github.com/mobz/elasticsearch-head
安装node
解压源码压缩包
cmd进入解压目录
npm install
npm run start
修改elasticsearch取消跨域限制的配置
vim elasticsearch.yml
在Network部分添加如下配置
http.cors.enabled: true
http.cors.allow-origin: "*"
浏览器访问ES-header
http://localhost:9100/
查看ES信息
GET http://192.168.3.26:9200

查看集群健康状态
GET http://192.168.3.26:9200/_cluster/health

-- index索引基础操作
删除index
DELETE http://192.168.3.26:9200/{indexName}
添加index
PUT http://192.168.3.26:9200/{indexName}
body json:
{
    "settings": {
        "index": {
            "number_of_shards": "3",
            "number_of_replicas": "0"
        }
    }
}
查看index详情
GET http://192.168.3.26:9200/{indexName}
查看所有index
GET http://192.168.3.26:9200/_cat/indices
查看所有index带上表头
http://192.168.3.26:9200/_cat/indices?v

-- mapping基础操作
定义index的数据结构，相当于定义表结构
创建索引并指定mapping
PUT http://10.30.25.76:9200/index_mapping
body json:
{
    "mappings": {
        "properties": {
            "realname": {
                "type": "text",
                "index": true
            },
            "username": {
                "type": "keyword",
                "index": false
            }
        }
    }
}
字段属性：
"type"：字段类型；text-会分词进行倒排索引，适合长文本。keyword-不会被分词，精确匹配字段内容就当做一个关键字，用于聚合和排序。
"index": 是否索引，默认为true，若设置为false，则该字段不可被检索到。一般保持默认，敏感信息必须设置为false不可被检索

analyze分词分析
GET http://192.168.3.26:9200/index_mapping/_analyze
body json:
{
    "field": "realname",
    "text": "wangdachui is very good!"
}
默认支持英文，中文另需扩展，realname可进行分词，有多个token，username则只有一个token

index已添加属性的类型设置后无法修改，除非删除字段，也可添加新字段以设置类型
POST http://192.168.3.26:9200/index_mapping/_mapping
{
    "properties": {
            "id": {
                "type": "long"
            },
            "age": {
                "type": "integer"
            }
        }
}
数据类型：
text,keyword
long,integer,short,byte
double,float
boolean
date
object
数组只能包含统一数据类型的值，需保证类型一致

-- document文档的基本操作
添加文档与自动映射
POST http://192.168.3.26:9200/my_doc/_doc/1
{
    "id": 1001,
    "name": "wangdachui-1",
    "desc": "happy every day!",
    "create_date": "2021-07-05"
}
URL中最后的1为es中的ID，也可去掉，ES会自动生成随机字符串作为ID
添加文档后会自动添加index的映射mapping，对于text类型字段，还会追加如下的mapping映射配置
"fields": {
    "keyword": {
    "ignore_above": 256,
    "type": "keyword"
}
该配置的作用为是的该字段既可以有text的分词匹配搜索，也可以使用keyword的聚合和排序，但是长度超过ignore_above的限制后就会失效

删除文档
DELETE http://192.168.3.26:9200/my_doc/_doc/1yUud3oBQWvv7NbxJwiN
url最后的是文档ID，删除是逻辑删除，只有当数据在磁盘中存储到一定程度后才会进行物理删除释放磁盘空间

更新文档指定字段的值
POST http://192.168.3.26:9200/my_doc/_doc/1/_update
body json:
{
    "doc": {
        "name": "更新的名字"
    }
}
全量更新文档
PUT http://192.168.3.26:9200/my_doc/_doc/1
body json:
{
    "id": 5551,
    "name": "id1 uodate name",
    "desc": "hello beauty!",
    "create_date": "2021-04-12"
}
修改删除_version都会累加

查询指定文档ID的文档信息
GET http://192.168.3.26:9200/my_doc/_doc/1

查询指定文档ID的文档信息，指定返回字段
GET http://192.168.3.26:9200/my_doc/_doc/1?_source=id,name

查询index下的所有文档
GET http://192.168.3.26:9200/my_doc/_doc/_search
其中took代表耗时，hits代表命中的记录数，max_score匹配度相关性分数，_source文档数据内容，GET请求Body需为none

查询index下的所有文档，指定返回字段
GET http://192.168.3.26:9200/my_doc/_doc/_search?_source=id,name

查询文档ID是否存在
HEAD http://192.168.3.26:9200/my_doc/_doc/1

-- 乐观锁
版本控制，如果更新的请求版本与实际版本不匹配，那么将拒绝更新
POST http://192.168.3.26:9200/my_doc/_doc/6/_update?if_seq_no=14&if_primary_term=5
_seq_no，与version类似，变更后累加
_primary_term，文档所在分片位置

-- 分词
将一段文字内容切分分析，把词汇单词切分出来
POST http://192.168.3.26:9200/_analyze
{
    "analyzer": "standard",
    "text": "I have strong muscles"
}
大写的内容分词后将转换为小写
指定index字段进行分词在前面的analyze分词分析已提到
分词器：
simple：按照非字母进行分词，也会将大写转换为小写，不是字母将会被去除
whitespace：根据空格进行分词，大写与标点会被保留
stop：去除is the a等词汇
keyword：将整段文本作为关键字

--中文分词器
https://github.com/medcl/elasticsearch-analysis-ik
安装ik中文分词器
unzip elasticsearch-analysis-ik-7.4.2.zip -d /usr/local/elasticsearch-7.4.2/plugins/ik
重启ES
分词器：
ik_max_word：将文本做最细粒度的拆分
ik_smart：将文本做最粗粒度的拆分
若文本未被分词，则搜索时无法匹配到，也就搜不到

--自定义词典
vim /usr/local/elasticsearch-7.4.2/plugins/ik/config/IKAnalyzer.cfg.xml
编辑配置：<entry key="ext_dict">custom.dic</entry>保存退出
统计目录创建词典文件：custom.dic，输入内容
骚年
柳叔
重启ES即可

-- DSL搜索
创建名为shop的index，mapping为如下内容：
{
    "properties":{
        "id":{
            "type":"long"
        },
        "age":{
            "type":"integer"
        },
        "username":{
            "type":"keyword"
        },
        "nickname":{
            "type":"text",
            "analyzer":"ik_max_word"
        },
        "money":{
            "type":"float"
        },
        "desc":{
            "type":"text",
            "analyzer":"ik_max_word"
        },
        "sex":{
            "type":"byte"
        },
        "birthday":{
            "type":"date"
        },
        "face":{
            "type":"text",
            "index": false
        }
    }
}

-- 查询
QueryString方式查询：复杂查询不方便，适用于简单查询，使用频率较少
GET http://192.168.3.26:9200/shop/_doc/_search?q=desc:不可怕&q=age:33
对于keyword类型，只搜索部分内容时搜索不到
GET http://192.168.3.26:9200/shop/_doc/_search?q=username:剪

搭建ES集群
修改集群名称为自定义
cluster.name: my-es-cluster
修改节点名称
node.name: es-node3-26
在network下添加配置
# 节点可成为master
node.master: true
# 节点可成为数据节点
node.data: true
配置集群节点IP
discovery.seed_hosts: ["192.168.3.17", "192.168.3.26", "192.168.3.27"]
配置主节点名
cluster.initial_master_nodes: ["es-node3-17"]
三台ES都进行如上配置，但是node.name需要修改为不一样的

当某一节点挂掉时，其节点上面的share主分片的身份会被转移到其他节点的replica上面去
节点恢复后原本的share身份变为replica，不会抢占回为主分片share身份
ES的master与主节点与副本的竞争机制为非抢占式
ES集群脑裂
如果发生网络中断或者服务器宕机，那么集群会有可能被划分为两个部分，各自有自己的master来管理，那么这就是脑裂。
脑裂解决方案：
master主节点要经过多个master节点共同选举后才能成为新的主节点。就跟班级里选班长一样，并不是你1个人能决定的，需要班里半数以上的人决定。
解决实现原理：半数以上的节点同意选举，节点方可成为新的master。
discovery.zen.minimum_master_nodes=(N/2)+1
N为集群的中master节点的数量，也就是那些 node.master=true 设置的那些服务器节点总数。
在最新版7.x中， minimum_master_node 这个参数已经被移除了，这一块内容完全由es自身去管理，这样就避免了脑裂的问题，选举也会非常快。



